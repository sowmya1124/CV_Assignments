{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ded3177d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: depthai in c:\\users\\owner\\anaconda3\\lib\\site-packages (2.25.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install depthai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d6ac8ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\owner\\anaconda3\\lib\\site-packages (4.9.0.80)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\owner\\anaconda3\\lib\\site-packages (from opencv-python) (1.24.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bedb6c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import depthai as dai\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73ee019",
   "metadata": {},
   "source": [
    "#### 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf1ac51d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\AppData\\Local\\Temp\\ipykernel_21604\\1247709747.py:19: DeprecationWarning: LEFT is deprecated, use CAM_B or address camera by name  instead.\n",
      "  left.setBoardSocket(dai.CameraBoardSocket.LEFT)\n",
      "C:\\Users\\Owner\\AppData\\Local\\Temp\\ipykernel_21604\\1247709747.py:22: DeprecationWarning: RIGHT is deprecated, use CAM_C or address camera by name  instead.\n",
      "  right.setBoardSocket(dai.CameraBoardSocket.RIGHT)\n"
     ]
    }
   ],
   "source": [
    "# Closer-in minimum depth, disparity range is doubled (from 95 to 190):\n",
    "extended_disp = False\n",
    "# Better accuracy for longer distance, fractional disparity 32-levels:\n",
    "sub_pixelel = False\n",
    "# Better handling for occlusions:\n",
    "lr_check = True\n",
    "\n",
    "# Create pipeline\n",
    "pipeline = dai.Pipeline()\n",
    "\n",
    "# camera configurations\n",
    "camera_rgb = pipeline.create(dai.node.ColorCamera)\n",
    "camera_rgb.setResolution(dai.ColorCameraProperties.SensorResolution.THE_1080_P)\n",
    "xout_rgb = pipeline.createXLinkOut()\n",
    "xout_rgb.setStreamName(\"rgb\")\n",
    "camera_rgb.video.link(xout_rgb.input)\n",
    "left = pipeline.createMonoCamera()\n",
    "left.setResolution(dai.MonoCameraProperties.SensorResolution.THE_400_P)\n",
    "left.setBoardSocket(dai.CameraBoardSocket.LEFT)\n",
    "right = pipeline.createMonoCamera()\n",
    "right.setResolution(dai.MonoCameraProperties.SensorResolution.THE_400_P)\n",
    "right.setBoardSocket(dai.CameraBoardSocket.RIGHT)\n",
    "depth = pipeline.createStereoDepth()\n",
    "left.out.link(depth.left)\n",
    "right.out.link(depth.right)\n",
    "xout = pipeline.createXLinkOut()\n",
    "xout.setStreamName(\"disparity\")\n",
    "depth.disparity.link(xout.input)\n",
    "\n",
    "prev_frame_time = 0\n",
    "new_frame_time = 0\n",
    "DIM = (720, 480)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "862bfb35",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Device already closed or disconnected: io error",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m dai\u001b[38;5;241m.\u001b[39mDevice(pipeline) \u001b[38;5;28;01mas\u001b[39;00m device:\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m# Output queue will be used to get the disparity frames from the outputs defined above\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     q \u001b[38;5;241m=\u001b[39m device\u001b[38;5;241m.\u001b[39mgetOutputQueue(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisparity\u001b[39m\u001b[38;5;124m\"\u001b[39m, maxSize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      5\u001b[0m     q_rgb \u001b[38;5;241m=\u001b[39m device\u001b[38;5;241m.\u001b[39mgetOutputQueue(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrgb\u001b[39m\u001b[38;5;124m\"\u001b[39m, maxSize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Device already closed or disconnected: io error"
     ]
    }
   ],
   "source": [
    "with dai.Device(pipeline) as device:\n",
    "\n",
    "    # Output queue will be used to get the disparity frames from the outputs defined above\n",
    "    q = device.getOutputQueue(name=\"disparity\", maxSize=4, blocking=False)\n",
    "    q_rgb = device.getOutputQueue(name=\"rgb\", maxSize=4, blocking=False)\n",
    "    while True:\n",
    "\n",
    "        new_frame_time = time.time()\n",
    "\n",
    "        fps = 1 / (new_frame_time - prev_frame_time)\n",
    "        prev_frame_time = new_frame_time\n",
    "        fps = int(fps)\n",
    "\n",
    "        in_rgb = q_rgb.get()\n",
    "\n",
    "        in_disparity = q.get()  # blocking call, will wait until a new data has arrived\n",
    "        frame = in_disparity.getFrame()\n",
    "\n",
    "        # Normalization for better visualization\n",
    "        frame = (frame * (255 / depth.initialConfig.getMaxDisparity())).astype(np.uint8)\n",
    "\n",
    "        frame_rgb = cv.resize(in_rgb.getCvFrame(), DIM, interpolation=cv.INTER_AREA)\n",
    "\n",
    "        cv.imshow(\"rgb\", frame_rgb)\n",
    "        cv.imshow(\"disparity\", frame)\n",
    "\n",
    "        print(\"FPS: \", fps)\n",
    "        if cv.waitKey(1) == ord('q'):\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4aa6d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import glob\n",
    "import time\n",
    "from pathlib import Path\n",
    "import depthai as dai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55507833",
   "metadata": {},
   "source": [
    "##### 1, 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52b8d8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    function to capture 10 images from mentioned source \n",
    "    - source can be RIGHT or LEFT monochrome camera of OAK D LITE\n",
    "    - images captured at 1000 sec interval\n",
    "    \n",
    "    params : \n",
    "    \n",
    "        src = {'right' || 'left'} (default : right)\n",
    "        delay = {delay in ms} (default : 1000)\n",
    "'''\n",
    "\n",
    "def captureImages(src='right', delay=1000):\n",
    "    if src != 'right' and src != 'left': \n",
    "        print(\"ENTER CORRECT PARAMS!\")\n",
    "        print(\"accepted params: {left, right} \")\n",
    "        print(f\"entered src:{src}\")\n",
    "        return;\n",
    "    \n",
    "    # Start defining a pipeline\n",
    "    pipeline = dai.Pipeline()\n",
    "\n",
    "    # Define a source - mono (grayscale) camera\n",
    "    # LEFT or RIGHT    \n",
    "    \n",
    "    cam = pipeline.createMonoCamera()\n",
    "    \n",
    "    if src == 'right' :\n",
    "        cam.setBoardSocket(dai.CameraBoardSocket.RIGHT)\n",
    "    else :\n",
    "        cam.setBoardSocket(dai.CameraBoardSocket.LEFT)\n",
    "\n",
    "    cam.setResolution(dai.MonoCameraProperties.SensorResolution.THE_480_P)\n",
    "\n",
    "    # Create output\n",
    "    xout = pipeline.createXLinkOut()\n",
    "    xout.setStreamName(src)\n",
    "    cam.out.link(xout.input)\n",
    "\n",
    "    # Connect and start the pipeline\n",
    "    with dai.Device(pipeline,usb2Mode=True) as device:\n",
    "\n",
    "        # Output queue will be used to get the grayscale frames from the output defined above\n",
    "        q = device.getOutputQueue(name=src, maxSize=4, blocking=False)\n",
    "\n",
    "        # Make sure the destination path is present before starting to store the examples\n",
    "        Path(f\"images/{src}\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        for i in range(10):\n",
    "            # Blocking call, will wait until a new data has arrived\n",
    "            inSrc = q.get()  \n",
    "            # Data is originally represented as a flat 1D array, it needs to be converted into HxW form\n",
    "            frame = inSrc.getCvFrame()\n",
    "            # Frame is transformed and ready to be shown\n",
    "            cv.imshow(src, frame)\n",
    "\n",
    "            cv.imwrite(f\"images/{src}/{int(time.time() * 10000)}.png\", frame)\n",
    "            cv.waitKey(delay)  \n",
    "\n",
    "            cv.destroyAllWindows()            \n",
    "\n",
    "\n",
    "def captureColorImages(delay=1000):\n",
    "    \n",
    "    # Start defining a pipeline\n",
    "    pipeline = dai.Pipeline()\n",
    "\n",
    "    # Define a source - color camera\n",
    "    \n",
    "    cam = pipeline.createColorCamera()\n",
    "    cam.setResolution(dai.ColorCameraProperties.SensorResolution.THE_1080_P)\n",
    "\n",
    "    # Create RGB output\n",
    "    xout = pipeline.createXLinkOut()\n",
    "    xout.setStreamName(\"rgb\")\n",
    "    cam.video.link(xout.input)\n",
    "\n",
    "    # Connect and start the pipeline\n",
    "    with dai.Device(pipeline,usb2Mode=True) as device:\n",
    "\n",
    "        # Output queue will be used to get the color frames from the output defined above\n",
    "        q = device.getOutputQueue(name=\"rgb\", maxSize=4, blocking=False)\n",
    "\n",
    "        # Make sure the destination path is present before starting to store the examples\n",
    "        Path(f\"images/rgb\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        for i in range(10):\n",
    "            # Blocking call, will wait until a new data has arrived\n",
    "            inSrc = q.get()  \n",
    "            # Data is originally represented as a flat 1D array, it needs to be converted into HxW form\n",
    "            frame = inSrc.getCvFrame()\n",
    "            # Frame is transformed and ready to be shown\n",
    "            imS = cv.resize(frame, (960, 540)) # Resize image\n",
    "            cv.imshow(\"rgb\", imS)   \n",
    "#             cv.imshow(\"rgb\", frame)\n",
    "\n",
    "            cv.imwrite(f\"images/rgb/{int(time.time() * 10000)}.png\", frame)\n",
    "            cv.waitKey(delay)  \n",
    "\n",
    "            cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "342bd27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    function to find corners, caliberate and store \n",
    "    camera matrix and distortion vector from mentioned source \n",
    "    - source can be RIGHT or LEFT monochrome camera or COLOR camera \n",
    "    of OAK D LITE\n",
    "    \n",
    "    params : \n",
    "        images = {array of image paths}\n",
    "        src = source file {'right' || 'left' || 'rgb'} \n",
    "'''\n",
    "\n",
    "def caliberate(images, src):\n",
    "    if src != 'right' and src != 'left' and src != 'rgb': \n",
    "        print(\"ENTER CORRECT PARAMS!\")\n",
    "        print(\"accepted params: {left, right, rgb} \")\n",
    "        print(f\"entered src:{src}\")\n",
    "        return;\n",
    "\n",
    "    \n",
    "    # termination criteria\n",
    "    criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "    # prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "    objp = np.zeros((6*9,3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)\n",
    "\n",
    "    # Arrays to store object points and image points from all the images.\n",
    "    objpoints = [] # 3d point in real world space\n",
    "    imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "    notFound = []\n",
    "\n",
    "#     img_size = () # will be using this for caliberation\n",
    "\n",
    "    for fname in images:\n",
    "        img = cv.imread(fname)\n",
    "        gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "        \n",
    "#         img_size = gray.shape[::-1]\n",
    "    \n",
    "        cv.imshow('gray', img)        \n",
    "        cv.waitKey(1000)\n",
    "        cv.destroyAllWindows()\n",
    "\n",
    "        # Finding chess board corners\n",
    "        ret, corners = cv.findChessboardCorners(gray, (9,6), None)\n",
    "\n",
    "        # If found, add object points, image points (after refining them)\n",
    "        if ret == True:\n",
    "            objpoints.append(objp)\n",
    "            corners2 = cv.cornerSubPix(gray,corners, (11,11), (-1,-1), criteria)\n",
    "            imgpoints.append(corners)\n",
    "\n",
    "            # Draw and display the corners\n",
    "            cv.drawChessboardCorners(img, (9,6),corners2, ret)\n",
    "            cv.imshow('img', img)\n",
    "\n",
    "            # Saving diplayed corners for future references\n",
    "            cv.imwrite(f\"{fname.split('.')[0]}_corners.png\", img)\n",
    "            cv.waitKey(1000)\n",
    "            cv.destroyAllWindows()\n",
    "        else :\n",
    "            # if corners not found, storing it into a list\n",
    "\n",
    "            notFound.append(fname)\n",
    "            print(f\"corners not found for {fname}\")\n",
    "\n",
    "    cv.destroyAllWindows()\n",
    "\n",
    "    # removing the pictures whose corners werent found\n",
    "    # from the main image list\n",
    "    for i in notFound:\n",
    "        images.remove(i)\n",
    "\n",
    "    # calibration\n",
    "    ret, mtx, dist, rvecs, tvecs = cv.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "        \n",
    "    for fname in images:\n",
    "        img = cv.imread(fname)\n",
    "        h,  w = img.shape[:2]\n",
    "        newcameramtx, roi = cv.getOptimalNewCameraMatrix(mtx, dist, (w,h), 1, (w,h))\n",
    "\n",
    "        # undistort\n",
    "        dst = cv.undistort(img, mtx, dist, None, newcameramtx)\n",
    "\n",
    "        # crop the image\n",
    "        x, y, w, h = roi\n",
    "        dst = dst[y:y+h, x:x+w]\n",
    "        \n",
    "        # save new image into file\n",
    "        cv.imwrite(f\"{fname.split('.')[0]}_result.png\", dst)\n",
    "        \n",
    "        \n",
    "    # we will be storing the camera matrix and \n",
    "    # distortion coefficients for future uses\n",
    "\n",
    "    print(\"Saving camera matrix...\")\n",
    "    camera_matrix = np.matrix(mtx)\n",
    "    with open(f\"images/{src}/camera_matrix.txt\",'wb') as f:\n",
    "        for line in camera_matrix:\n",
    "            np.savetxt(f, line, fmt='%.5f')\n",
    "            \n",
    "    print(\"Saving distortion vector...\")\n",
    "    distortion_vector = np.matrix(dist)\n",
    "    with open(f\"images/{src}/distortion_matrix.txt\",'wb') as f:\n",
    "        for line in distortion_vector:\n",
    "            np.savetxt(f, line, fmt='%.5f')\n",
    "            \n",
    "    \n",
    "    print(\"Saving rotational vectors ...\")\n",
    "    rotation_vectors = np.array(rvecs)\n",
    "    with open(f\"images/{src}/rotat_vector.txt\",'wb') as f:\n",
    "        for vector in rotation_vectors:\n",
    "            vector = np.reshape(vector, (1,3))\n",
    "            np.savetxt(f, vector, fmt='%.5f')\n",
    "            \n",
    "    print(\"Saving translation vectors...\")\n",
    "    translation_vectors = np.array(tvecs)\n",
    "    with open(f\"images/{src}/trans_vector.txt\",'wb') as f:\n",
    "        for vector in translation_vectors:\n",
    "            vector = np.reshape(vector, (1,3))\n",
    "            np.savetxt(f, vector, fmt='%.5f')\n",
    "            \n",
    "    print('Done!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d20f8919",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\AppData\\Local\\Temp\\ipykernel_21604\\3467920802.py:28: DeprecationWarning: RIGHT is deprecated, use CAM_C or address camera by name  instead.\n",
      "  cam.setBoardSocket(dai.CameraBoardSocket.RIGHT)\n",
      "C:\\Users\\Owner\\AppData\\Local\\Temp\\ipykernel_21604\\3467920802.py:40: DeprecationWarning: Use constructor taking 'UsbSpeed' instead\n",
      "  with dai.Device(pipeline,usb2Mode=True) as device:\n",
      "C:\\Users\\Owner\\AppData\\Local\\Temp\\ipykernel_21604\\3467920802.py:30: DeprecationWarning: LEFT is deprecated, use CAM_B or address camera by name  instead.\n",
      "  cam.setBoardSocket(dai.CameraBoardSocket.LEFT)\n",
      "C:\\Users\\Owner\\AppData\\Local\\Temp\\ipykernel_21604\\3467920802.py:78: DeprecationWarning: Use constructor taking 'UsbSpeed' instead\n",
      "  with dai.Device(pipeline,usb2Mode=True) as device:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corners not found for images/right\\17132232119207.png\n",
      "corners not found for images/right\\17132232129884.png\n",
      "corners not found for images/right\\17132232151002.png\n",
      "corners not found for images/right\\17132232193151.png\n",
      "corners not found for images/right\\17132232203740.png\n",
      "corners not found for images/right\\17132232214171.png\n",
      "Saving camera matrix...\n",
      "Saving distortion vector...\n",
      "Saving rotational vectors ...\n",
      "Saving translation vectors...\n",
      "Done!!\n",
      "corners not found for images/rgb\\17132232434939.png\n",
      "corners not found for images/rgb\\17132232445946.png\n",
      "corners not found for images/rgb\\17132232457044.png\n",
      "corners not found for images/rgb\\17132232479436.png\n",
      "corners not found for images/rgb\\17132232490395.png\n",
      "corners not found for images/rgb\\17132232501700.png\n",
      "corners not found for images/rgb\\17132232523973.png\n",
      "corners not found for images/rgb\\17132232534950.png\n",
      "Saving camera matrix...\n",
      "Saving distortion vector...\n",
      "Saving rotational vectors ...\n",
      "Saving translation vectors...\n",
      "Done!!\n",
      "corners not found for images/left\\17132232276522.png\n",
      "corners not found for images/left\\17132232287082.png\n",
      "corners not found for images/left\\17132232297445.png\n",
      "corners not found for images/left\\17132232318329.png\n",
      "corners not found for images/left\\17132232328985.png\n",
      "corners not found for images/left\\17132232339511.png\n",
      "corners not found for images/left\\17132232350031.png\n",
      "corners not found for images/left\\17132232360555.png\n",
      "corners not found for images/left\\17132232371080.png\n",
      "Saving camera matrix...\n",
      "Saving distortion vector...\n",
      "Saving rotational vectors ...\n",
      "Saving translation vectors...\n",
      "Done!!\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    calling function to capture images\n",
    "    \n",
    "    I have used the previously declared function to \n",
    "    capture 10 images of a chessboard \n",
    "    \n",
    "    these images are then used to caliberate the camera\n",
    "    i used a 8x6 chess board for caliberations purposes\n",
    "    \n",
    "'''\n",
    "\n",
    "# capturing images using right monochrome camera\n",
    "captureImages('right')\n",
    "\n",
    "# capturing images using left monochrome camera\n",
    "captureImages('left')\n",
    "\n",
    "# capturing images using color camera\n",
    "captureColorImages()\n",
    "right_images = glob.glob('images/right/*.png')\n",
    "color_images = glob.glob('images/rgb/*.png')\n",
    "left_images = glob.glob('images/left/*.png')\n",
    "\n",
    "# bruh_images = glob.glob('images/bruh/*.png')\n",
    "\n",
    "caliberate(right_images, 'right')\n",
    "caliberate(color_images, 'rgb')\n",
    "caliberate(left_images, 'left') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8f9323",
   "metadata": {},
   "outputs": [],
   "source": [
    "right_images = glob.glob('images/right/*.png')\n",
    "color_images = glob.glob('images/rgb/*.png')\n",
    "left_images = glob.glob('images/left/*.png')\n",
    "\n",
    "# bruh_images = glob.glob('images/bruh/*.png')\n",
    "\n",
    "caliberate(right_images, 'right')\n",
    "caliberate(color_images, 'rgb')\n",
    "caliberate(left_images, 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa55bc2a",
   "metadata": {},
   "source": [
    "#### 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81e53a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import glob\n",
    "import time\n",
    "from pathlib import Path\n",
    "import depthai as dai\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1126d52",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimages/right/camera_matrix.txt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m f :\n\u001b[1;32m----> 5\u001b[0m         camera_matrix\u001b[38;5;241m.\u001b[39mappend([\u001b[38;5;28mfloat\u001b[39m(num) \u001b[38;5;28;01mfor\u001b[39;00m num \u001b[38;5;129;01min\u001b[39;00m line\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)])\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCAMERA INTRINSIC MATRIX:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(camera_matrix)\n",
      "Cell \u001b[1;32mIn[3], line 5\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimages/right/camera_matrix.txt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m f :\n\u001b[1;32m----> 5\u001b[0m         camera_matrix\u001b[38;5;241m.\u001b[39mappend([\u001b[38;5;28mfloat\u001b[39m(num) \u001b[38;5;28;01mfor\u001b[39;00m num \u001b[38;5;129;01min\u001b[39;00m line\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)])\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCAMERA INTRINSIC MATRIX:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(camera_matrix)\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: ''"
     ]
    }
   ],
   "source": [
    "camera_matrix = []\n",
    " \n",
    "with open('images/right/camera_matrix.txt', 'r') as f:\n",
    "    for line in f :\n",
    "        camera_matrix.append([float(num) for num in line.split(' ')])\n",
    "\n",
    "print(\"CAMERA INTRINSIC MATRIX:\")\n",
    "print(camera_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9312d2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "FX = 525\n",
    "FY = 525\n",
    "Z = 320"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f07bc8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_milli_to_inch(x):\n",
    "    x = x / 10\n",
    "    return x / 25.4\n",
    "image = cv.imread(\"cv object image.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0ca7dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, w, h =15,16,18,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a25b33e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.142857142857142\n",
      "9.752380952380953\n",
      "20.114285714285714\n",
      "20.114285714285714\n",
      "Diameter of blue cirlce: 11.883000000000001\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[ 41,  60,  68],\n",
       "        [ 46,  65,  73],\n",
       "        [ 48,  67,  75],\n",
       "        ...,\n",
       "        [123, 137, 149],\n",
       "        [123, 137, 149],\n",
       "        [131, 145, 157]],\n",
       "\n",
       "       [[ 25,  44,  52],\n",
       "        [ 31,  50,  58],\n",
       "        [ 34,  53,  61],\n",
       "        ...,\n",
       "        [153, 167, 179],\n",
       "        [124, 138, 150],\n",
       "        [108, 122, 134]],\n",
       "\n",
       "       [[ 53,  70,  79],\n",
       "        [ 53,  70,  79],\n",
       "        [ 47,  64,  73],\n",
       "        ...,\n",
       "        [164, 178, 190],\n",
       "        [164, 178, 190],\n",
       "        [179, 193, 205]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 65,  77,  89],\n",
       "        [ 63,  75,  87],\n",
       "        [ 61,  73,  85],\n",
       "        ...,\n",
       "        [104, 119, 128],\n",
       "        [ 99, 114, 123],\n",
       "        [101, 116, 125]],\n",
       "\n",
       "       [[ 44,  56,  68],\n",
       "        [ 42,  54,  66],\n",
       "        [ 40,  52,  64],\n",
       "        ...,\n",
       "        [139, 154, 163],\n",
       "        [141, 156, 165],\n",
       "        [136, 151, 160]],\n",
       "\n",
       "       [[ 21,  33,  45],\n",
       "        [ 20,  32,  44],\n",
       "        [ 21,  33,  45],\n",
       "        ...,\n",
       "        [238, 253, 255],\n",
       "        [234, 249, 255],\n",
       "        [212, 227, 236]]], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 5)\n",
    "Image_point1x = x\n",
    "Image_point1y = y\n",
    "Image_point2x = x + w\n",
    "Image_point2y = y + h\n",
    "cv.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 5)\n",
    "cv.line(image, (Image_point1x, Image_point1y), (Image_point1x, Image_point2y), (0, 0, 255), 8)\n",
    "Real_point1x = Z * (Image_point1x / FX)\n",
    "Real_point1y = Z * (Image_point1y / FY)\n",
    "Real_point2x = Z * (Image_point2x / FX)\n",
    "Real_point2y = Z * (Image_point2x / FY)\n",
    "print(Real_point1x)\n",
    "print(Real_point1y)\n",
    "print(Real_point2x)\n",
    "print(Real_point2y)\n",
    "dist = math.sqrt((Real_point2y - Real_point1y) ** 2 + (Real_point2x - Real_point1x) ** 2)\n",
    "val = round(convert_milli_to_inch(dist*2), 5)\n",
    "print(\"Diameter of blue cirlce: {}\".format(val*100))\n",
    "cv.putText(image, str(val) + \" inches\", (Image_point1x-200, (y + y + h) // 2 + 5),cv.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c64bf24",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 46\u001b[0m\n\u001b[0;32m     44\u001b[0m image_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv_object_image.jpeg\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     45\u001b[0m camera_matrix_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimages/right/camera_matrix.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 46\u001b[0m diameter_cm \u001b[38;5;241m=\u001b[39m get_circle_diameter(image_path, camera_matrix_path)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDiameter of blue circle: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m cm\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(diameter_cm))\n",
      "Cell \u001b[1;32mIn[8], line 13\u001b[0m, in \u001b[0;36mget_circle_diameter\u001b[1;34m(image_path, camera_matrix_path)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(camera_matrix_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m f:\n\u001b[1;32m---> 13\u001b[0m         camera_matrix\u001b[38;5;241m.\u001b[39mappend([\u001b[38;5;28mfloat\u001b[39m(num) \u001b[38;5;28;01mfor\u001b[39;00m num \u001b[38;5;129;01min\u001b[39;00m line\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)])\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Load image\u001b[39;00m\n\u001b[0;32m     16\u001b[0m image \u001b[38;5;241m=\u001b[39m cv\u001b[38;5;241m.\u001b[39mimread(image_path)\n",
      "Cell \u001b[1;32mIn[8], line 13\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(camera_matrix_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m f:\n\u001b[1;32m---> 13\u001b[0m         camera_matrix\u001b[38;5;241m.\u001b[39mappend([\u001b[38;5;28mfloat\u001b[39m(num) \u001b[38;5;28;01mfor\u001b[39;00m num \u001b[38;5;129;01min\u001b[39;00m line\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)])\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Load image\u001b[39;00m\n\u001b[0;32m     16\u001b[0m image \u001b[38;5;241m=\u001b[39m cv\u001b[38;5;241m.\u001b[39mimread(image_path)\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: ''"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import math\n",
    "\n",
    "def get_circle_diameter(image_path, camera_matrix_path):\n",
    "    def convert_milli_to_cm(x):\n",
    "        x = x / 10\n",
    "        return x / 25.4\n",
    "\n",
    "    # Load camera matrix\n",
    "    camera_matrix = []\n",
    "    with open(camera_matrix_path, 'r') as f:\n",
    "        for line in f:\n",
    "            camera_matrix.append([float(num) for num in line.split(' ')])\n",
    "\n",
    "    # Load image\n",
    "    image = cv.imread(image_path)\n",
    "\n",
    "    # Define points (you may need to adjust these values)\n",
    "    x, y, w, h = 15, 16, 13, 1\n",
    "    Image_point1x = x\n",
    "    Image_point1y = y\n",
    "    Image_point2x = x + w\n",
    "    Image_point2y = y + h\n",
    "\n",
    "    # Draw rectangle and line on the image\n",
    "    cv.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 5)\n",
    "    cv.line(image, (Image_point1x, Image_point1y), (Image_point1x, Image_point2y), (0, 0, 255), 8)\n",
    "\n",
    "    # Calculate real world points\n",
    "    Z = 310\n",
    "    FX = camera_matrix[0][0]\n",
    "    FY = camera_matrix[1][1]\n",
    "    Real_point1x = Z * (Image_point1x / FX)\n",
    "    Real_point1y = Z * (Image_point1y / FY)\n",
    "    Real_point2x = Z * (Image_point2x / FX)\n",
    "    Real_point2y = Z * (Image_point2y / FY)\n",
    "\n",
    "    # Calculate diameter in pixels\n",
    "    dist = math.sqrt((Real_point2y - Real_point1y) ** 2 + (Real_point2x - Real_point1x) ** 2)\n",
    "\n",
    "    return dist\n",
    "\n",
    "# Example usage:\n",
    "image_path = \"cv_object_image.jpeg\"\n",
    "camera_matrix_path = \"images/right/camera_matrix.txt\"\n",
    "diameter_cm = get_circle_diameter(image_path, camera_matrix_path)\n",
    "print(\"Diameter of blue circle: {} cm\".format(diameter_cm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7804df8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808e36d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
